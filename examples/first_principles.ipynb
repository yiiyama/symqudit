{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e23c68a0-c2c6-49db-9d79-5817eb6463e9",
   "metadata": {},
   "source": [
    "# Reproduction of First-principles analysis of cross-resonance gate operation\n",
    "\n",
    "Malekakhlagh et al. PRA 102, 042605\n",
    "\n",
    "Note that the drive frequency is set to the undressed target qubit frequency, which results in $\\mathcal{O}(J^2)$ differences in the calculation results compared to ideal experimental observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597de84-01df-40c3-b853-0446b0205183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from sympy import Add, Expr, I, Mul, Pow, S, Symbol, diff, pi, simplify\n",
    "from sympy.physics.quantum import Commutator, IdentityOperator, HermitianOperator, TensorProduct\n",
    "from symqudit.two_transmon_hamiltonian import (TwoTransmonHamiltonian, sort_block_diagonal,\n",
    "                                               to_dict, from_dict, dict_product)\n",
    "from symqudit.schrieffer_wolff_expansion import SWExpansion, integrate_exp_term, integrate_expr\n",
    "from symqudit.common import ketbra, get_expr_at_order, organize_by_denom\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa0760-290d-4c8b-9a9a-8f6c7ce89da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Id = IdentityOperator()\n",
    "t = Symbol('t', real=True)\n",
    "\n",
    "def expand_opprod(lhs, rhs, blkdiag_only=False) -> dict[tuple, Expr]:\n",
    "    start = time.time()\n",
    "    op_prod = dict_product(op_dicts[lhs], op_dicts[rhs],\n",
    "                           blkdiag_only=blkdiag_only, expand=False)\n",
    "\n",
    "    if blkdiag_only:\n",
    "        filtered = {}\n",
    "        for ket, bra_dict in op_prod.items():\n",
    "            filtered[ket] = {}\n",
    "            for bra, coeff in bra_dict.items():\n",
    "                coeff = coeff.expand()\n",
    "                if isinstance(coeff, Add):\n",
    "                    cterms = coeff.args\n",
    "                else:\n",
    "                    cterms = [coeff]\n",
    "                cterms = [cterm for cterm in cterms if diff(cterm, t) is S.Zero]\n",
    "                if cterms:\n",
    "                    filtered[ket][bra] = Add(*cterms)\n",
    "\n",
    "            if not filtered[ket]:\n",
    "                filtered.pop(ket)\n",
    "\n",
    "        op_prod = filtered\n",
    "        \n",
    "    end = time.time()\n",
    "    logger.info('dict_product(%s, %s) in %f seconds', lhs, rhs, end - start)\n",
    "\n",
    "    return op_prod\n",
    "\n",
    "\n",
    "def calculate_commutator(fore, back):\n",
    "    result = copy.deepcopy(fore)\n",
    "    for ket, bra_dict in back.items():\n",
    "        if ket not in result:\n",
    "            result[ket] = defaultdict(lambda: S.Zero)\n",
    "        for bra, coeff in bra_dict.items():\n",
    "            result[ket][bra] -= coeff\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def expand_expr(expr):\n",
    "    return expr.expand()\n",
    "\n",
    "\n",
    "def sort_static(coeff):\n",
    "    coeff = coeff.expand()\n",
    "    if isinstance(coeff, Add):\n",
    "        terms = coeff.args\n",
    "    else:\n",
    "        terms = [coeff]\n",
    "\n",
    "    s_terms = []\n",
    "    d_terms = []\n",
    "    \n",
    "    for term in terms:\n",
    "        if diff(term, t) is S.Zero:\n",
    "            s_terms.append(term)\n",
    "        else:\n",
    "            d_terms.append(term)\n",
    "\n",
    "    if s_terms:\n",
    "        s_terms = Add(*s_terms)\n",
    "    else:\n",
    "        s_terms = None\n",
    "    if d_terms:\n",
    "        d_terms = Add(*d_terms)\n",
    "    else:\n",
    "        d_terms = None\n",
    "\n",
    "    return s_terms, d_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81330e6-af59-4180-a021-e2e70a5ba13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_dict_parallel(terms):\n",
    "    ops = []\n",
    "    coeffs = []\n",
    "    \n",
    "    for ket, bra_dict in terms.items():\n",
    "        for bra, coeff in bra_dict.items():\n",
    "            coeffs.append(coeff)\n",
    "            if ket[1] is None:\n",
    "                ops.append(TensorProduct(ketbra(ket[0], bra[0]), Id))\n",
    "            else:\n",
    "                ops.append(TensorProduct(ketbra(ket[0], bra[0]), ketbra(ket[1], bra[1])))\n",
    "                \n",
    "    with Pool() as pool:\n",
    "        coeffs = pool.map(expand_expr, coeffs)\n",
    "\n",
    "    return Add(*[c * o for c, o in zip(coeffs, ops)])\n",
    "\n",
    "\n",
    "def sort_block_diagonal_parallel(all_terms):\n",
    "    maybe_blkdiag = []\n",
    "    nonblkdiag = defaultdict(dict)\n",
    "\n",
    "    for ket, bra_dict in all_terms.items():\n",
    "        for bra, coeff in bra_dict.items():\n",
    "            if ket[0] == bra[0]:\n",
    "                maybe_blkdiag.append((ket, bra, coeff))\n",
    "            else:\n",
    "                nonblkdiag[ket][bra] = coeff\n",
    "\n",
    "    blkdiag = defaultdict(dict)\n",
    "    if maybe_blkdiag:\n",
    "        with Pool() as pool:\n",
    "            sorted_coeffs = pool.map(sort_static, [c for _, _, c in maybe_blkdiag])\n",
    "\n",
    "        for (s_terms, d_terms), (ket, bra, _) in zip(sorted_coeffs, maybe_blkdiag):\n",
    "            if s_terms is not None:\n",
    "                blkdiag[ket][bra] = s_terms\n",
    "            if d_terms is not None:\n",
    "                nonblkdiag[ket][bra] = d_terms\n",
    "\n",
    "    return blkdiag, nonblkdiag\n",
    "\n",
    "\n",
    "def integrate_expr_parallel(nonblkdiag):\n",
    "    flattened = [(ket, bra, coeff) for ket, bra_dict in nonblkdiag.items() for bra, coeff in bra_dict.items()]\n",
    "    with Pool() as pool:\n",
    "        coeffs = pool.map(expand_expr, [coeff for _, _, coeff in flattened])\n",
    "    \n",
    "    coeff_terms = []\n",
    "    term_bounds = [0]\n",
    "    for coeff in coeffs:\n",
    "        if isinstance(coeff, Add):\n",
    "            coeff_terms += list(coeff.args)\n",
    "        else:\n",
    "            coeff_terms.append(coeff)\n",
    "        term_bounds.append(len(coeff_terms))\n",
    "\n",
    "    with Pool() as pool:\n",
    "        int_terms = pool.map(integrate_exp_term, coeff_terms)\n",
    "    \n",
    "    integrated = defaultdict(dict)\n",
    "    for iterm, (ket, bra, _) in enumerate(flattened):\n",
    "        integrated[ket][bra] = Add(*int_terms[term_bounds[iterm]:term_bounds[iterm + 1]])\n",
    "\n",
    "    return integrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2694e7-64d1-4c08-b287-98b13bf99aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 4\n",
    "c_params = (100., 0.1)\n",
    "t_params = (104., 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0308638-5f31-4e86-84a3-59b78f3020f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tth = TwoTransmonHamiltonian((c_params[0], t_params[0]), (c_params[1], t_params[1]))\n",
    "\n",
    "h_dirac = tth.h_dirac(cutoff=cutoff).expand()\n",
    "h_dirac = h_dirac.subs({tth.drive_freq: tth.qt.symbolic_eigenvalue(1).doit(), tth.drive_phase: pi})\n",
    "h_dirac = tth.subs_delta(h_dirac).expand()\n",
    "subs = {}\n",
    "for transmon in [tth.qc, tth.qt]:\n",
    "    for level in range(cutoff):\n",
    "        nu = transmon._transition_amp(level, level + 1)\n",
    "        subs[nu] = Symbol(nu._latex(None), real=True)\n",
    "h_dirac = h_dirac.subs(subs)\n",
    "\n",
    "int_scale = Symbol('lambda', real=True, nonnegative=True)\n",
    "h_i = HermitianOperator('H_I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5748cad-35fa-490c-a919-9666a83a2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_heff_at_order(order, blkdiag_only=False):\n",
    "    comm_expr = get_expr_at_order(expansion, int_scale, order) + sw.gdot_n[order]\n",
    "\n",
    "    start = time.time()\n",
    "    if order == 1:\n",
    "        # No commutator for Order 位 -> just substitute H_I\n",
    "        states_expr[order] = comm_expr.subs({h_i: h_dirac})\n",
    "        all_terms = to_dict(states_expr[order])\n",
    "\n",
    "    else:\n",
    "        while True:\n",
    "            if isinstance(comm_expr, Add):\n",
    "                terms = comm_expr.args\n",
    "            else:\n",
    "                terms = [comm_expr]\n",
    "            for term in terms:\n",
    "                comm = term.args_cnc()[1][0]\n",
    "                if isinstance(comm.args[0], Commutator) or isinstance(comm.args[1], Commutator):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "            new_expr = comm_expr.subs(commutator_subs)\n",
    "            if new_expr == comm_expr:\n",
    "                raise RuntimeError('Cannot reduce commutator %s', comm_expr)\n",
    "            comm_expr = new_expr\n",
    "\n",
    "        coeffs = []\n",
    "        commutators = []\n",
    "        opprod_terms = []\n",
    "        for term in terms:\n",
    "            c, nc = term.args_cnc()\n",
    "            coeff = Mul(*c)\n",
    "            comm = nc[0]\n",
    "            if isinstance(comm, Mul):\n",
    "                coeff *= comm.args[0]\n",
    "                comm = comm.args[1]\n",
    "            coeffs.append(coeff)\n",
    "            commutators.append(comm)\n",
    "            opprod_terms.append((comm.args[0], comm.args[1]))\n",
    "            opprod_terms.append((comm.args[1], comm.args[0]))\n",
    "        \n",
    "        with Pool() as pool:\n",
    "            if blkdiag_only:\n",
    "                args = [arg + (True,) for arg in opprod_terms]\n",
    "            else:\n",
    "                args = opprod_terms\n",
    "            opprods = pool.starmap(expand_opprod, args)\n",
    "            \n",
    "        end = time.time()\n",
    "        logger.info('expand_opprod for order %d in %f seconds', order, end - start)\n",
    "        start = end\n",
    "        \n",
    "        comm_dicts_source = list(zip(opprods[0:-1:2], opprods[1::2]))\n",
    "        with Pool() as pool:\n",
    "            comm_dicts = pool.starmap(calculate_commutator, comm_dicts_source)\n",
    "            \n",
    "        end = time.time()\n",
    "        logger.info('calculate_commutator for order %d in %f seconds', order, end - start)\n",
    "        start = end\n",
    "        \n",
    "        all_terms = defaultdict(lambda: defaultdict(lambda: S.Zero))\n",
    "        for coeff, comm, comm_dict in zip(coeffs, commutators, comm_dicts):\n",
    "            if not blkdiag_only:\n",
    "                placeholder = HermitianOperator(f'C_{len(commutator_subs)}')\n",
    "                commutator_subs[comm] = placeholder\n",
    "                op_dicts[placeholder] = comm_dict\n",
    "\n",
    "            for ket, bra_dict in comm_dict.items():\n",
    "                for bra, c in bra_dict.items():\n",
    "                    all_terms[ket][bra] += coeff * c\n",
    "                \n",
    "        end = time.time()\n",
    "        logger.info('all_terms compilation for order %d in %f seconds', order, end - start)\n",
    "        start = end\n",
    "\n",
    "        # Expression in terms of TensorProduct(OuterProduct, OuterProduct or Identity)\n",
    "        states_expr[order] = from_dict_parallel(all_terms)\n",
    "\n",
    "    if blkdiag_only:\n",
    "        hieff[order] = states_expr[order]\n",
    "        return\n",
    "\n",
    "    blkdiag, nonblkdiag = sort_block_diagonal_parallel(all_terms)\n",
    "    hieff[order] = from_dict_parallel(blkdiag)\n",
    "    gdot[order] = from_dict_parallel(nonblkdiag)\n",
    "    \n",
    "    end = time.time()\n",
    "    logger.info('sort_block_diagonal(%d) in %f seconds', order, end - start)\n",
    "    start = end\n",
    "    \n",
    "    integrated = integrate_expr_parallel(nonblkdiag)\n",
    "    g[order] = from_dict_parallel(integrated)\n",
    "    \n",
    "    end = time.time()\n",
    "    logger.info('integrate_expr(%d) in %f seconds', order, end - start)\n",
    "\n",
    "    op_dicts.update({sw.g_n[order]: to_dict(g[order]), sw.gdot_n[order]: to_dict(gdot[order])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311688f2-9753-4e7b-b26c-7f126ee8ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "op_dicts = {h_i: to_dict(h_dirac)}\n",
    "states_expr = {}\n",
    "commutator_subs = {}\n",
    "g = {}\n",
    "gdot = {}\n",
    "hieff = {}\n",
    "\n",
    "sw = SWExpansion()\n",
    "expansion = sw.expand(int_scale * h_i, int_scale, 4)\n",
    "\n",
    "## Order 位\n",
    "calc_heff_at_order(1)\n",
    "\n",
    "# Special substitution\n",
    "expansion = expansion.subs({sw.gdot_n[1]: h_i})\n",
    "\n",
    "## Order 位^2\n",
    "calc_heff_at_order(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c1d6b0-da9e-46a2-bce7-2320b3484879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compos = tth.pauli_components(hieff[2], 2, 2)\n",
    "\n",
    "for idx in [(0, 1), (3, 0), (3, 1), (3, 3)]:\n",
    "    display(compos[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627023b9-9e2e-4356-9ccf-6622ef4b6ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order 位^3\n",
    "calc_heff_at_order(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f922b68-8502-4437-a9c2-8f3eeaf326d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_heff_at_order(4, blkdiag_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9c955-2ca5-49cf-8ad9-66801056bd94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compos = tth.pauli_components(hieff[4], 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0992e4-8710-40b7-9964-60cb5d467d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_principle_qutrit.pkl', 'wb') as out:\n",
    "    pickle.dump((hieff, g, gdot), out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
